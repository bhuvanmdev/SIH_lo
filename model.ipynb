{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24a1fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D,Input\n",
    "from tensorflow.nn import relu\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pydot,graphviz\n",
    "from IPython.display import Image\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "# import numpy as np\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_texture_conv = False\n",
    "use_shape_conv = False\n",
    "texture_downsample = False\n",
    "probe_pt = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d306d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_dims_1_to_4(tensor, dims=None):\n",
    "    if not dims:\n",
    "        dims = [-1, -1, -1]\n",
    "    return tf.expand_dims(\n",
    "             tf.expand_dims(\n",
    "               tf.expand_dims(tensor, axis=dims[0]),\n",
    "               axis=dims[1]),\n",
    "             axis=dims[2])\n",
    "\n",
    "def res_manipulator(enc_a,\n",
    "                    enc_b,\n",
    "                    amplification_factor,\n",
    "                    layer_dims=32,\n",
    "                    num_resblk=1,\n",
    "                    num_conv=0,\n",
    "                    num_aft_conv=0,\n",
    "                    probe_pt=probe_pt):\n",
    "    diff = (enc_b - enc_a)\n",
    "    if probe_pt is not None:\n",
    "        probe_pt[\"mani_diff\"] = diff\n",
    "    for i in range(num_conv):\n",
    "        p = 3\n",
    "        k = 7\n",
    "        diff = tf.pad(diff, [[0, 0], [p, p], [p, p], [0, 0]], \"REFLECT\")\n",
    "        cname = f'mani_conv_{i}'\n",
    "        diff = Conv2D(layer_dims, kernel_size=k, strides=1, activation='relu', name=cname + 'c',kernel_initializer=TruncatedNormal(stddev=0.2))(diff)\n",
    "    if probe_pt is not None:\n",
    "        probe_pt[\"mani_after_conv\"] = diff\n",
    "    diff = diff * expand_dims_1_to_4(amplification_factor - 1.0)\n",
    "    if probe_pt is not None:\n",
    "        probe_pt[\"mani_after_mult\"] = diff\n",
    "    for i in range(num_aft_conv):\n",
    "        diff = tf.pad(diff, [[0, 0], [1, 1], [1, 1], [0, 0]], \"REFLECT\")\n",
    "        cname = f'mani_aft_conv_{i}'\n",
    "        diff = Conv2D(layer_dims, kernel_size=3, strides=1, name=cname + 'c',kernel_initializer=TruncatedNormal(stddev=0.2))(diff)\n",
    "    for i in range(num_resblk):\n",
    "        diff = residual_block(diff, layer_dims, 3, 1, name=f'mani_resblk{i}')\n",
    "    if probe_pt is not None:\n",
    "        probe_pt[\"mani_after_res\"] = diff\n",
    "    return enc_b + diff\n",
    "\n",
    "\n",
    "def res_encoder(image, no,layer_dims=32, num_resblk=5):\n",
    "    c0 = tf.pad(image, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\")\n",
    "    c1 = Conv2D(layer_dims // 2, kernel_size=7, strides=1,activation='relu', name='res_enc_conv1_c'+no,kernel_initializer=TruncatedNormal(stddev=0.2))(c0)\n",
    "    c2 = Conv2D(layer_dims, kernel_size=3, strides=2,activation='relu', name='res_enc_conv2_c'+no,kernel_initializer=TruncatedNormal(stddev=0.2))(c1)\n",
    "    # Define G network with num_resblk resnet blocks\n",
    "    r = c2\n",
    "    for i in range(num_resblk):\n",
    "        r = residual_block(r, layer_dims, 3, 1, name=f'res_encoder_resblk{i}_'+no)\n",
    "    \n",
    "    return r\n",
    "\n",
    "\n",
    "\n",
    "def res_decoder(activation,\n",
    "                layer_dims=64,\n",
    "                out_channels=3,\n",
    "                num_resblk=4):\n",
    "    r = activation\n",
    "    for i in range(num_resblk):\n",
    "        r = residual_block(r, layer_dims, 3, 1, name=f'res_decoder_resblk{i}')\n",
    "    \n",
    "    up = tf.image.resize(r, tf.shape(r)[1:3] * 2)\n",
    "    up = tf.pad(up, [[0, 0], [1, 1], [1, 1], [0, 0]], \"REFLECT\")\n",
    "    d2 = Conv2D(layer_dims // 2, kernel_size=3, strides=1, activation='relu',name='res_dec_conv2_c',kernel_initializer=TruncatedNormal(stddev=0.2))(up)\n",
    "    d2 = tf.pad(d2, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\")\n",
    "    out = Conv2D(out_channels, kernel_size=7, strides=1, name='res_pred_conv',kernel_initializer=TruncatedNormal(stddev=0.2))(d2)\n",
    "    #i put this\n",
    "    return tf.pad(out, [[0, 0], [1, 1], [1, 1], [0, 0]], \"REFLECT\")\n",
    "\n",
    "# Define the residual_block function\n",
    "\n",
    "\n",
    "\n",
    "def residual_block(x, output_dim, ks=3, s=1, name='residual_block'):\n",
    "    p = (ks - 1) // 2\n",
    "    y = tf.pad(x, [[0, 0], [p, p], [p, p], [0, 0]], \"REFLECT\")\n",
    "    y = Conv2D(output_dim, ks, s, activation='relu',name=name+'_c1',kernel_initializer=TruncatedNormal(stddev=0.2))(y)\n",
    "    y = tf.pad(y, [[0, 0], [p, p], [p, p], [0, 0]], \"REFLECT\")\n",
    "    y = Conv2D(output_dim, ks, s, name=name+'_c2',kernel_initializer=TruncatedNormal(stddev=0.2))(y)\n",
    "    return y + x\n",
    "\n",
    "def _encoder(image,no):\n",
    "    enc = res_encoder(image,no)\n",
    "\n",
    "    texture_enc = enc\n",
    "    shape_enc = enc\n",
    "    # first convolution on common encoding\n",
    "    if use_texture_conv:\n",
    "        stride = 2 if texture_downsample else 1###making sure it is downsampled or not\n",
    "        texture_enc = Conv2D(32, 3, stride,activation='relu',name='enc_texture_conv_'+no,kernel_initializer=TruncatedNormal(stddev=0.2))(texture_enc)\n",
    "    \n",
    "    if use_shape_conv:\n",
    "        shape_enc = Conv2D(32, 3, 1,activation='relu', name='enc_shape_conv_'+no,kernel_initializer=TruncatedNormal(stddev=0.2))(shape_enc)\n",
    "\n",
    "    for i in range(1):\n",
    "        name = f'texture_enc_{i}_'+no\n",
    "        if i == 0:\n",
    "            # for backward compatibility\n",
    "            name = 'texture_enc__'+no\n",
    "        texture_enc = residual_block(texture_enc, 32, 3, 1,'resblk_'+name)\n",
    "\n",
    "    for i in range(1):\n",
    "        name = f'shape_enc_{i}_'+no\n",
    "        if i == 0:\n",
    "            # for backward compatibility\n",
    "            name = 'shape_enc__'+no\n",
    "        shape_enc = residual_block(shape_enc, 32,\n",
    "                                   3, 1, 'resblk_'+name)\n",
    "    return texture_enc, shape_enc\n",
    "\n",
    "def _decoder(texture_enc, shape_enc):\n",
    "    if texture_downsample:\n",
    "        texture_enc = tf.image.resize(\n",
    "                        texture_enc,\n",
    "                        tf.shape(texture_enc)[1:3]* 2)\n",
    "        texture_enc = tf.pad(texture_enc, [[0, 0], [1, 1], [1, 1], [0, 0]],\n",
    "                             \"REFLECT\")\n",
    "        texture_enc = Conv2D(32,3, 1,activation='relu',name='texture_upsample',kernel_initializer=TruncatedNormal(stddev=0.2))(texture_enc)\n",
    "\n",
    "    enc = tf.concat([texture_enc, shape_enc], axis=3)\n",
    "    # Needs double the channel because we concat the two encodings.\n",
    "    return res_decoder(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e1c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_a = Input((450,450,3))\n",
    "img_b = Input((450,450,3))\n",
    "_,s_a = _encoder(img_a,'1')\n",
    "t_b,s_b = _encoder(img_b,'2')\n",
    "ou = res_manipulator(s_b,s_a,10)\n",
    "out = _decoder(t_b,ou)\n",
    "model = Model(inputs=[img_a,img_b],outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.compile(optimizer='adam', loss=(lambda x,y:tf.reduce_mean(tf.abs(x - y))), metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df2592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo u were asking me about how weights are stored right? this is how! ''sim'' list contains all trainable wieghts \n",
    "# sim = [(x,model.layers[x].weights) for x in range(len(model.layers)) if model.layers[x].weights!=[]]\n",
    "sim[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d13f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf2b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model,'img.jpeg',show_shapes=True,\n",
    "#     show_dtype=True,\n",
    "#     show_layer_names=True,\n",
    "#     rankdir='TB',\n",
    "#     expand_nested=True,\n",
    "#     show_layer_activations=True,\n",
    "#     show_trainable=True)\n",
    "# # Image('img.jpeg')\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "   feature_description = {\n",
    "        'frameA': tf.io.FixedLenFeature([], tf.string),\n",
    "        'frameB': tf.io.FixedLenFeature([], tf.string),\n",
    "        'frameC': tf.io.FixedLenFeature([], tf.string),\n",
    "        'frameAmp': tf.io.FixedLenFeature([], tf.string),\n",
    "        'amplification_factor': tf.io.FixedLenFeature([], tf.float32)\n",
    "    }\n",
    "\n",
    "    # Parse the example\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    \n",
    "    # Decode the images from bytes\n",
    "    frameA = tf.image.decode_image(example['frameA'])\n",
    "    frameB = tf.image.decode_image(example['frameB'])\n",
    "    frameC = tf.image.decode_image(example['frameC'])\n",
    "    frameAmp = tf.image.decode_image(example['frameAmp'])\n",
    "\n",
    "    return frameA, frameB, frameC, frameAmp, example['amplification_factor']\n",
    "\n",
    "\n",
    "filenames = 'tf record path'\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "dataset = dataset.map(parse_tfrecord_fn)\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(20)\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c965eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_stuff",
   "language": "python",
   "name": "ai_stuff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
